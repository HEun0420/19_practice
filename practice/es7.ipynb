{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redis URL: redis://:dlp@localhost:6379\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Redis URL 가져오기\n",
    "REDIS_URL = os.getenv('REDIS_URL')\n",
    "\n",
    "print(f\"Redis URL: {REDIS_URL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Redis란 무엇인가?'에 대한 검색 결과:\n",
      "- Redis는 강력한 인메모리 데이터베이스입니다.\n",
      "- LangChain은 AI 애플리케이션 개발을 위한 프레임워크입니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_redis import RedisVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Redis URL 설정\n",
    "REDIS_URL = os.getenv('REDIS_URL')\n",
    "\n",
    "# 벡터 스토어 초기화\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = RedisVectorStore(embeddings, redis_url=REDIS_URL)\n",
    "\n",
    "# 문서 추가\n",
    "docs = [\n",
    "    Document(page_content=\"Redis는 강력한 인메모리 데이터베이스입니다.\"),\n",
    "    Document(page_content=\"LangChain은 AI 애플리케이션 개발을 위한 프레임워크입니다.\")\n",
    "]\n",
    "vector_store.add_documents(docs)\n",
    "\n",
    "# 유사도 검색 실행\n",
    "query = \"Redis란 무엇인가?\"\n",
    "results = vector_store.similarity_search(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(f\"'{query}'에 대한 검색 결과:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_redis import RedisChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat History:\n",
      "HumanMessage: 안녕 봇!\n",
      "AIMessage: 그래 안녕...?\n"
     ]
    }
   ],
   "source": [
    "# Initialize RedisChatMessageHistory\n",
    "history = RedisChatMessageHistory(session_id=\"user_123\", redis_url=REDIS_URL)\n",
    "\n",
    "# Add messages to the history\n",
    "history.add_user_message(\"안녕 봇!\")\n",
    "history.add_ai_message(\"그래 안녕...?\")\n",
    "\n",
    "# Retrieve messages\n",
    "print(\"Chat History:\")\n",
    "for message in history.messages:\n",
    "    print(f\"{type(message).__name__}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key found in environment variables.\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# Check if OPENAI_API_KEY is already set in the environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"OpenAI API key not found in environment variables.\")\n",
    "    openai_api_key = getpass(\"Please enter your OpenAI API key: \")\n",
    "\n",
    "    # Set the API key for the current session\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    print(\"OpenAI API key has been set for this session.\")\n",
    "else:\n",
    "    print(\"OpenAI API key found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response 1: Hello, Alice! How can I assist you today?\n",
      "AI Response 2: Your name is Alice.\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Create the conversational chain\n",
    "chain = prompt | llm\n",
    "\n",
    "\n",
    "# Function to get or create a RedisChatMessageHistory instance\n",
    "def get_redis_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    return RedisChatMessageHistory(session_id, redis_url=REDIS_URL)\n",
    "\n",
    "\n",
    "# Create a runnable with message history\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain, get_redis_history, input_messages_key=\"input\", history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# Use the chain in a conversation\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hi, my name is Alice.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"alice_123\"}},\n",
    ")\n",
    "print(\"AI Response 1:\", response1.content)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What's my name?\"}, config={\"configurable\": {\"session_id\": \"alice_123\"}}\n",
    ")\n",
    "print(\"AI Response 2:\", response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom History: [HumanMessage(content='This is a message with custom configuration.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Initialize with custom Redis configuration\n",
    "custom_history = RedisChatMessageHistory(\n",
    "    \"user_456\",\n",
    "    redis_url=REDIS_URL,\n",
    "    key_prefix=\"custom_prefix:\",\n",
    "    ttl=3600,  # Set TTL to 1 hour\n",
    "    index_name=\"custom_index\",\n",
    ")\n",
    "\n",
    "custom_history.add_user_message(\"This is a message with custom configuration.\")\n",
    "print(\"Custom History:\", custom_history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "human: Tell me about artificial intelligence....\n",
      "ai: Artificial Intelligence (AI) is a branch of comput...\n"
     ]
    }
   ],
   "source": [
    "# Add more messages\n",
    "history.add_user_message(\"Tell me about artificial intelligence.\")\n",
    "history.add_ai_message(\n",
    "    \"Artificial Intelligence (AI) is a branch of computer science...\"\n",
    ")\n",
    "\n",
    "# Search for messages containing a specific term\n",
    "search_results = history.search_messages(\"artificial intelligence\")\n",
    "print(\"Search Results:\")\n",
    "for result in search_results:\n",
    "    print(f\"{result['type']}: {result['content'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages after clearing: []\n"
     ]
    }
   ],
   "source": [
    "# Clear the chat history\n",
    "history.clear()\n",
    "print(\"Messages after clearing:\", history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20111\\AppData\\Local\\Temp\\ipykernel_14980\\1753710674.py:28: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"history\")\n",
      "C:\\Users\\20111\\AppData\\Local\\Temp\\ipykernel_14980\\1753710674.py:31: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=llm, memory=memory)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 무엇을 도와드릴까요?\n",
      "챗봇:  Hello there! How may I assist you?\n",
      "\n",
      "--- 현재 단기 기억 ---\n",
      "{'history': 'Human: \\nAI:  Hello there! How may I assist you?'}\n",
      "----------------------\n",
      "챗봇:  Sure, I can definitely help you with that! Based on your location and the time of day, I would recommend checking out a nearby Italian restaurant called \"Pasta Paradise.\" They have a great selection of pasta dishes and their dinner specials include a delicious pesto chicken dish. Would you like me to provide directions or the restaurant's contact information for you?\n",
      "\n",
      "--- 현재 단기 기억 ---\n",
      "{'history': 'Human: \\nAI:  Hello there! How may I assist you?\\nHuman: 추천해줄 저녁메뉴\\nAI:  Sure, I can definitely help you with that! Based on your location and the time of day, I would recommend checking out a nearby Italian restaurant called \"Pasta Paradise.\" They have a great selection of pasta dishes and their dinner specials include a delicious pesto chicken dish. Would you like me to provide directions or the restaurant\\'s contact information for you?'}\n",
      "----------------------\n",
      "챗봇:  Hello there! I am an AI and I am always happy to help with any questions or tasks you may have. Is there anything specific you would like assistance with?\n",
      "\n",
      "--- 현재 단기 기억 ---\n",
      "{'history': 'Human: \\nAI:  Hello there! How may I assist you?\\nHuman: 추천해줄 저녁메뉴\\nAI:  Sure, I can definitely help you with that! Based on your location and the time of day, I would recommend checking out a nearby Italian restaurant called \"Pasta Paradise.\" They have a great selection of pasta dishes and their dinner specials include a delicious pesto chicken dish. Would you like me to provide directions or the restaurant\\'s contact information for you?\\nHuman: 안녕아년ㅇ?\\nAI:  Hello there! I am an AI and I am always happy to help with any questions or tasks you may have. Is there anything specific you would like assistance with?'}\n",
      "----------------------\n",
      "챗봇:  I apologize if I am not able to answer your question or provide assistance at the moment. Is there a specific topic or task you would like me to focus on? I am always learning and improving, so I will do my best to assist you.\n",
      "\n",
      "--- 현재 단기 기억 ---\n",
      "{'history': 'Human: \\nAI:  Hello there! How may I assist you?\\nHuman: 추천해줄 저녁메뉴\\nAI:  Sure, I can definitely help you with that! Based on your location and the time of day, I would recommend checking out a nearby Italian restaurant called \"Pasta Paradise.\" They have a great selection of pasta dishes and their dinner specials include a delicious pesto chicken dish. Would you like me to provide directions or the restaurant\\'s contact information for you?\\nHuman: 안녕아년ㅇ?\\nAI:  Hello there! I am an AI and I am always happy to help with any questions or tasks you may have. Is there anything specific you would like assistance with?\\nHuman: 저기 있잖아 지금 대답이 안되는거같은데?\\nAI:  I apologize if I am not able to answer your question or provide assistance at the moment. Is there a specific topic or task you would like me to focus on? I am always learning and improving, so I will do my best to assist you.'}\n",
      "----------------------\n",
      "챗봇을 종료합니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from langchain_redis import RedisChatMessageHistory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Redis URL 및 OpenAI API 키 로드\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "\n",
    "# 고유한 session_id 생성 (예: UUID 사용)\n",
    "session_id = str(uuid.uuid4())  # UUID로 고유한 session_id 생성\n",
    "\n",
    "# Redis에 연결하여 메시지 이력 관리 객체 생성\n",
    "message_history = RedisChatMessageHistory(redis_url=REDIS_URL, session_id=session_id)\n",
    "\n",
    "# OpenAI 모델 설정 (프롬프트에 따라 동적으로 응답을 생성)\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "# ConversationBufferMemory를 사용하여 메모리 처리\n",
    "memory = ConversationBufferMemory(memory_key=\"history\")\n",
    "\n",
    "# 대화 체인 초기화 (Redis 메시지 기록을 사용하는 ConversationChain)\n",
    "conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "# 사용자 입력을 받아 응답을 생성하는 함수\n",
    "def chat_with_bot(user_input):\n",
    "    # 챗봇에게 입력을 주고, 대답을 받기\n",
    "    response = conversation.predict(input=user_input)\n",
    "    return response\n",
    "\n",
    "# 단기 기억 기능을 활용한 대화 예시\n",
    "print(\"안녕하세요! 무엇을 도와드릴까요?\")\n",
    "\n",
    "# 대화 예시: 사용자가 처음 질문을 했을 때\n",
    "while True:\n",
    "    user_input = input(\"나: \")\n",
    "\n",
    "    # 종료 조건 설정\n",
    "    if user_input.lower() in ['exit', 'quit', '종료']:\n",
    "        print(\"챗봇을 종료합니다. 감사합니다!\")\n",
    "        break\n",
    "    \n",
    "    # 단기 기억을 활용한 대화 흐름\n",
    "    response = chat_with_bot(user_input)\n",
    "    print(f\"챗봇: {response}\")\n",
    "\n",
    "    # 대화 이력 출력 (단기 기억 상태)\n",
    "    print(\"\\n--- 현재 단기 기억 ---\")\n",
    "    print(memory.load_memory_variables({}))\n",
    "    print(\"----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redis URL: redis://:dlp@localhost:6379\n",
      "Redis Password: dlp\n",
      "Redis Port: 6379\n",
      "Redis Web Port: 8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20111\\AppData\\Local\\Temp\\ipykernel_14980\\4259667146.py:37: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 1: Redis란 무엇인가요?\n",
      "답변 1:  Redis는 오픈 소스 데이터베이스 시스템으로서, 메모리 내에서 데이터를 저장하고 접근할 수 있는 기능을 제공합니다. 주로 캐싱, 세션 관리, 메시지 브로커 등의 용도로 사용됩니다. 데이터를 디스크에도 저장할 수 있어서 영속성을 제공하며, 다양한 데이터 구조를 지원하여 복잡한 작업을 간단하게 처리할 수 있습니다. Redis는 빠른 속도와 간편한 사용성으로 널리 사용되고 있습니다.\n",
      "\n",
      "질문 2: LangChain이 무엇인가요?\n",
      "답변 2: 죄송합니다. LangChain에 대해서는 알려드릴 수 없습니다.\n",
      "\n",
      "질문 3: Python은 무엇에 사용되나요?\n",
      "답변 3: Python은 다양한 용도로 사용되는 프로그래밍 언어입니다. 웹 개발, 데이터 분석, 인공지능, 자동화, 게임 개발 등 다양한 분야에서 사용됩니다. 파이썬은 문법이 간결하고 읽기 쉬워서 입문자들이 쉽게 배울 수 있으며, 다양한 라이브러리와 프레임워크를 지원하여 빠르고 효율적인 개발이 가능합니다.\n",
      "\n",
      "질문 4: 인공지능의 주요 응용 분야는 무엇인가요?\n",
      "답변 4: 인공지능의 주요 응용 분야는 의료, 금융, 마케팅, 제조 및 로봇 공학 등이 있습니다. 의료 분야에서는 질병 진닝, 의료 이미지 분석, 약물 개발 등에 사용됩니다. 금융 분야에서는 사기 탐지, 자산 관리, 신용평가 등에 활용됩니다. 마케팅에서는 고객 행동 예측, 개인화된 광고 등에 사용됩니다. 제조 및 로봇 공학 분야에서는 자동화, 로봇 제어, 생산 최적화 등에 활용됩니다.\n",
      "\n",
      "질문 5: Redis의 TTL 기능이란 무엇인가요?\n",
      "답변 5: Redis의 TTL(Time-To-Live) 기능은 Redis 데이터베이스에서 특정 키의 수명을 설정하는 기능입니다. TTL 값을 설정하면 해당 키는 설정된 시간이 지난 후 자동으로 삭제됩니다. 이를 통해 데이터의 만료 및 자동 정리가 가능해지며, 캐시나 세션 관리 등에 유용하게 활용됩니다.\n",
      "\n",
      "질문 6: LangChain의 Memory는 어떤 역할을 하나요?\n",
      "답변 6: 죄송합니다. LangChain의 Memory에 대한 정보는 제 데이터베이스에 없습니다.\n",
      "\n",
      "단기 기억 내용:\n",
      "1: Q: LangChain의 Memory는 어떤 역할을 하나요?\n",
      "A: 죄송합니다. LangChain의 Memory에 대한 정보는 제 데이터베이스에 없습니다.\n",
      "2: Q: Redis의 TTL 기능이란 무엇인가요?\n",
      "A: Redis의 TTL(Time-To-Live) 기능은 Redis 데이터베이스에서 특정 키의 수명을 설정하는 기능입니다. TTL 값을 설정하면 해당 키는 설정된 시간이 지난 후 자동으로 삭제됩니다. 이를 통해 데이터의 만료 및 자동 정리가 가능해지며, 캐시나 세션 관리 등에 유용하게 활용됩니다.\n",
      "3: Q: 인공지능의 주요 응용 분야는 무엇인가요?\n",
      "A: 인공지능의 주요 응용 분야는 의료, 금융, 마케팅, 제조 및 로봇 공학 등이 있습니다. 의료 분야에서는 질병 진닝, 의료 이미지 분석, 약물 개발 등에 사용됩니다. 금융 분야에서는 사기 탐지, 자산 관리, 신용평가 등에 활용됩니다. 마케팅에서는 고객 행동 예측, 개인화된 광고 등에 사용됩니다. 제조 및 로봇 공학 분야에서는 자동화, 로봇 제어, 생산 최적화 등에 활용됩니다.\n"
     ]
    }
   ],
   "source": [
    "## 리밋(10개) 제한 (v)\n",
    "## 특정 시간이 지나면 redis 저장소에서 자동 삭제 (v) (20초)\n",
    "## 세션(redis 서버(docker 서버))가 닫히면 자동 삭제 (v) (이거 실행 잘못하면 container 다시 설치하고 다시 비밀번호 셋팅해야함...<<이 사람이 아까 녹은 이유)\n",
    "\n",
    "import os\n",
    "import redis\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 로드\n",
    "REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379')  # 기본값 설정\n",
    "REDIS_PASSWORD = os.getenv('REDIS_PASSWORD', '')\n",
    "REDIS_PORT = os.getenv('REDIS_PORT', 6379)\n",
    "REDIS_WEB_PORT = os.getenv('REDIS_WEB_PORT', 8001)\n",
    "\n",
    "print(f\"Redis URL: {REDIS_URL}\")\n",
    "print(f\"Redis Password: {REDIS_PASSWORD}\")\n",
    "print(f\"Redis Port: {REDIS_PORT}\")\n",
    "print(f\"Redis Web Port: {REDIS_WEB_PORT}\")\n",
    "\n",
    "redis_client = redis.StrictRedis.from_url(REDIS_URL, decode_responses=True)\n",
    "\n",
    "# 단기 기억 크기 설정\n",
    "MAX_MEMORY_SIZE = 3  # 최대 저장할 메시지 수\n",
    "TTL = 20  # 단기 기억 유효 시간 (20초)\n",
    "\n",
    "# 사용자 세션 ID (여기서는 예시로 고정값 사용, 실제 서비스에서는 유저별 고유 ID 생성 필요)\n",
    "session_id = \"unique_session_id\"\n",
    "short_term_memory_key = f\"user_short_term_memory:{session_id}\"\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# LangChain 메모리 설정\n",
    "conversation_memory = ConversationBufferMemory(memory_key=\"history\")\n",
    "\n",
    "# ConversationChain 생성\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=conversation_memory\n",
    ")\n",
    "\n",
    "# Redis에 단기 기억 저장 함수\n",
    "def add_to_short_term_memory(query, response):\n",
    "    message = f\"Q: {query}\\nA: {response}\"\n",
    "    redis_client.lpush(short_term_memory_key, message)\n",
    "    redis_client.expire(short_term_memory_key, TTL)  # TTL 설정\n",
    "    redis_client.ltrim(short_term_memory_key, 0, MAX_MEMORY_SIZE - 1)  # 최대 크기 유지\n",
    "\n",
    "# Redis에서 단기 기억 로드 함수\n",
    "def load_short_term_memory():\n",
    "    return redis_client.lrange(short_term_memory_key, 0, -1)\n",
    "\n",
    "# LangChain 메모리와 Redis 동기화 함수\n",
    "def sync_memory():\n",
    "    messages = load_short_term_memory()\n",
    "    if messages:\n",
    "        conversation_memory.clear()  # 기존 메모리 초기화\n",
    "        for message in reversed(messages):  # 최신 메시지가 마지막에 오도록\n",
    "            q, a = message.split(\"\\nA: \")\n",
    "            q = q.replace(\"Q: \", \"\")\n",
    "            conversation_memory.chat_memory.add_user_message(q)\n",
    "            conversation_memory.chat_memory.add_ai_message(a)\n",
    "\n",
    "# 대화 함수\n",
    "def chat(query):\n",
    "    sync_memory()  # 단기 기억 동기화\n",
    "    try:\n",
    "        response = conversation.predict(input=query)\n",
    "        add_to_short_term_memory(query, response)  # Redis에 대화 내용 저장\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        return \"오류가 발생했습니다. 다시 시도해주세요.\"\n",
    "\n",
    "# 예시 대화\n",
    "if __name__ == \"__main__\":\n",
    "    # 여러 질문을 던져 단기 기억이 10개를 초과하도록 테스트\n",
    "    queries = [\n",
    "        \"Redis란 무엇인가요?\",\n",
    "        \"LangChain이 무엇인가요?\",\n",
    "        \"Python은 무엇에 사용되나요?\",\n",
    "        \"인공지능의 주요 응용 분야는 무엇인가요?\",\n",
    "        \"Redis의 TTL 기능이란 무엇인가요?\",\n",
    "        \"LangChain의 Memory는 어떤 역할을 하나요?\",\n",
    "    ]\n",
    "\n",
    "    # 각 질문에 대한 답변 출력\n",
    "    for i, query in enumerate(queries, start=1):\n",
    "        print(f\"질문 {i}: {query}\")\n",
    "        response = chat(query)\n",
    "        print(f\"답변 {i}: {response}\\n\")\n",
    "\n",
    "    # 단기 기억 내용 확인\n",
    "    short_term_memory = load_short_term_memory()\n",
    "    print(\"단기 기억 내용:\")\n",
    "    for i, memory in enumerate(short_term_memory, start=1):\n",
    "        print(f\"{i}: {memory}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단기 기억이 사라졌습니다.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 데이터를 Redis에 저장\n",
    "add_to_short_term_memory(\"질문1\", \"답변1\")\n",
    "\n",
    "# 30초 대기\n",
    "time.sleep(30)\n",
    "\n",
    "# 30초 단기 기억 확인\n",
    "short_term_memory = load_short_term_memory()\n",
    "\n",
    "if short_term_memory:\n",
    "    print(\"단기 기억 내용:\", short_term_memory)\n",
    "else:\n",
    "    print(\"단기 기억이 사라졌습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단기 기억이 사라졌습니다.\n"
     ]
    }
   ],
   "source": [
    "# Redis 서버 재시작 후 다시 확인\n",
    "short_term_memory = load_short_term_memory()\n",
    "\n",
    "if short_term_memory:\n",
    "    print(\"단기 기억 내용:\", short_term_memory)\n",
    "else:\n",
    "    print(\"단기 기억이 사라졌습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
